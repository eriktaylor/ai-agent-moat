name: Publish pipeline outputs (PR)

on:
  workflow_run:
    workflows: ["Weekly Pipeline (read-only)"]
    types: [completed]

permissions:
  contents: write
  pull-requests: write

jobs:
  create-pr:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest

    steps:
      - name: Checkout (full history to create/update PR branch)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # â¬‡ï¸ Download artifacts produced by the triggering run
      - name: Download pipeline artifacts from triggering run
        uses: dawidd6/action-download-artifact@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          run_id: ${{ github.event.workflow_run.id }}
          name: pipeline-results                  # must match uploader name exactly
          path: _results
          repo: ${{ github.repository }}

      - name: Show downloaded artifact contents (debug)
        run: |
          echo "Downloaded files:"
          ls -R _results || true

      - name: Place results into repo working tree
        run: |
          set -euxo pipefail
          mkdir -p data/search_cache
          shopt -s nullglob

          # CSVs
          cp -f _results/*.csv data/ 2>/dev/null || true

          # Cache JSONs + manifest-based deletion
          cp -f _results/*.json data/search_cache/ 2>/dev/null || true
          if [ -f _results/_manifest_cache.txt ]; then
            sort -u _results/_manifest_cache.txt > _results/_keep.txt
            for f in data/search_cache/*.json; do
              [ -e "$f" ] || continue
              base=$(basename "$f")
              if ! grep -qx "$base" _results/_keep.txt; then
                git rm -f -- "$f"
              fi
            done
          fi

      - name: Create Pull Request
        uses: peter-evans/create-pull-request@v6
        with:
          branch: bot/pipeline-results
          title: "ðŸ“ˆ Weekly pipeline results"
          body: |
            Automated outputs from the scheduled pipeline.

            - Updated base data (prices, fundamentals, SPY)
            - Candidates & agentic CSVs
            - Search cache (synced with TTL)
          commit-message: "chore: weekly pipeline outputs (data refresh + CSVs + cache sync)"
          add-paths: |
            data/*.csv
            data/search_cache/*.json
            data/search_cache/_manifest_cache.txt
          delete-branch: true
