{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5TGQ7TC_Go2"
      },
      "source": [
        "# AI Agent for Market Research & Competitive Analysis\n",
        "\n",
        "This application serves as an interactive demo for a sophisticated AI research agent. Simply enter a company name and stock ticker to generate a multi-faceted analysis from four distinct investor perspectives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh_9PsNs_Go5"
      },
      "source": [
        "## Step 1: API Key Setup\n",
        "\n",
        "Before running this agent, you need two free API keys from Google. Follow these instructions carefully.\n",
        "\n",
        "### 1. Get Your Google AI Studio API Key (`GOOGLE_API_KEY`)\n",
        "\n",
        "1.  Go to **[Google AI Studio](https://aistudio.google.com/app/apikey)**.\n",
        "2.  Click **\"Create API key in new project\"**.\n",
        "3.  Copy the generated API key.\n",
        "\n",
        "### 2. Get Your Google Programmable Search Engine Keys (`GOOGLE_CSE_ID`)\n",
        "\n",
        "This is a two-part process to get a Search Engine ID and enable the API.\n",
        "\n",
        "**Part A: Create the Search Engine**\n",
        "1.  Go to the **[Programmable Search Engine control panel](https://programmablesearchengine.google.com/controlpanel/all)**.\n",
        "2.  Click **\"Add\"** to create a new search engine.\n",
        "3.  Name your search engine (e.g., \"AI Agent Search\").\n",
        "4.  Crucially, select the option to **\"Search the entire web\"**.\n",
        "5.  After it's created, go to the \"Basics\" tab and find the **\"Search engine ID\"**. Copy this ID.\n",
        "\n",
        "**Part B: Enable the Custom Search API**\n",
        "1.  Go to the **[Google Cloud Console API Library](https://console.cloud.google.com/apis/library/customsearch.googleapis.com)**.\n",
        "2.  Ensure the project selected in the top navigation bar is the same one you created for your Google AI Studio key.\n",
        "3.  Click the **\"Enable\"** button. If it's already enabled, you're all set.\n",
        "\n",
        "### 3. Add Keys to Colab Secrets Manager\n",
        "\n",
        "1.  In this notebook, click the **key icon (🔑)** in the left sidebar.\n",
        "2.  Create a new secret named `GOOGLE_API_KEY` and paste your Google AI Studio key.\n",
        "3.  Create another new secret named `GOOGLE_CSE_ID` and paste your Search Engine ID."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QgJpgEi_Go6"
      },
      "source": [
        "## Step 2: Install Dependencies & Setup Environment\n",
        "\n",
        "This cell installs the required libraries, clones the project repository from GitHub to make the custom modules available, and sets up the necessary API keys for the agent to function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LEYo3RF_Go7"
      },
      "outputs": [],
      "source": [
        "import importlib\n",
        "import os\n",
        "import sys\n",
        "import requests\n",
        "import re\n",
        "import subprocess\n",
        "from google.colab import userdata\n",
        "\n",
        "def check_and_install_dependencies():\n",
        "    requirements_url = 'https://raw.githubusercontent.com/eriktaylor/ai-agent-moat/main/requirements.txt'\n",
        "    try:\n",
        "        response = requests.get(requirements_url)\n",
        "        response.raise_for_status()\n",
        "        requirements = response.text.splitlines()\n",
        "\n",
        "        import_name_map = {\n",
        "            'faiss-cpu': 'faiss',\n",
        "            'PyMuPDF': 'fitz',\n",
        "            'google-api-python-client': 'googleapiclient',\n",
        "            'beautifulsoup4': 'bs4',\n",
        "            'sentence-transformers': 'sentence_transformers'\n",
        "        }\n",
        "\n",
        "        missing_packages = False\n",
        "        for req in requirements:\n",
        "            if req.strip() and not req.startswith('#'):\n",
        "                package_name = re.split('[<>=~]=', req)[0].strip()\n",
        "                import_name = import_name_map.get(package_name, package_name.replace('-', '_'))\n",
        "                if not importlib.util.find_spec(import_name):\n",
        "                    missing_packages = True\n",
        "                    break\n",
        "\n",
        "        if missing_packages:\n",
        "            print(\"Installing dependencies from requirements.txt...\")\n",
        "            !pip install -q -r {requirements_url}\n",
        "            print(\"Installation complete.\")\n",
        "        else:\n",
        "            print(\"All dependencies are already installed.\")\n",
        "\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error fetching requirements.txt: {e}\")\n",
        "        print(\"Proceeding with default installation...\")\n",
        "        !pip install -q -r {requirements_url}\n",
        "\n",
        "check_and_install_dependencies()\n",
        "\n",
        "repo_path = 'ai-agent-moat'\n",
        "if os.path.exists(repo_path):\n",
        "    print(\"Repository already exists. Pulling latest changes...\")\n",
        "    try:\n",
        "        result = subprocess.run(['git', '-C', repo_path, 'pull'], capture_output=True, text=True, check=True)\n",
        "        print(result.stdout)\n",
        "        if 'Already up to date.' not in result.stdout:\n",
        "            print(\"\\nIMPORTANT: New updates were pulled from GitHub. Please restart the runtime to ensure all changes are loaded correctly (Runtime > Restart session).\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error pulling repository: {e.stderr}\")\n",
        "else:\n",
        "    print(f\"Cloning repository...\")\n",
        "    !git clone https://github.com/eriktaylor/ai-agent-moat.git\n",
        "\n",
        "if repo_path not in sys.path:\n",
        "    sys.path.append(repo_path)\n",
        "    print(f\"Added {repo_path} to system path.\")\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ['GOOGLE_CSE_ID'] = userdata.get('GOOGLE_CSE_ID')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Candidate Generation"
      ],
      "metadata": {
        "id": "Z_dsBBuP_S4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 3: Interactive Quantitative Screening & Candidate Generation ---\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# --- Part 1: Helper Functions (Largely unchanged) ---\n",
        "\n",
        "def get_sp500_tickers():\n",
        "    \"\"\"Fetches S&P 500 holdings from the SSGA website.\"\"\"\n",
        "    # (This function is the same as before)\n",
        "    print(\"Fetching S&P 500 tickers from SSGA...\")\n",
        "    try:\n",
        "        url = 'https://www.ssga.com/us/en/intermediary/etfs/library-content/products/fund-data/etfs/us/holdings-daily-us-en-spy.xlsx'\n",
        "        df = pd.read_excel(url, engine='openpyxl', skiprows=4).dropna(subset=['Ticker'])\n",
        "        tickers = [str(ticker).replace(' ', '-') for ticker in df['Ticker'].tolist() if isinstance(ticker, str)]\n",
        "        print(f\"✅ Successfully fetched {len(tickers)} tickers.\")\n",
        "        return tickers\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error fetching S&P 500 tickers: {e}\")\n",
        "        return []\n",
        "\n",
        "def fetch_financial_data(tickers):\n",
        "    \"\"\"Fetches key financial data for a list of stock tickers.\"\"\"\n",
        "    # (This function is the same as before)\n",
        "    all_stock_data = []\n",
        "    print(f\"Fetching financial data for {len(tickers)} stocks... (This may take 10-15 minutes)\")\n",
        "    pbar = tqdm(total=len(tickers), desc=\"Fetching data\")\n",
        "    for ticker in tickers:\n",
        "        try:\n",
        "            stock = yf.Ticker(ticker)\n",
        "            info = stock.info\n",
        "            if 'marketCap' in info and info['marketCap'] is not None:\n",
        "                all_stock_data.append(info)\n",
        "        except Exception:\n",
        "            continue\n",
        "        finally:\n",
        "            pbar.update(1)\n",
        "    pbar.close()\n",
        "    print(f\"\\n✅ Successfully fetched data for {len(all_stock_data)} stocks.\")\n",
        "    return pd.DataFrame(all_stock_data)\n",
        "\n",
        "def screen_and_score_stocks(df, weights):\n",
        "    \"\"\"Screens and scores a DataFrame of stocks based on user-defined weights.\"\"\"\n",
        "    # (This function is the same as before)\n",
        "    # --- Data Cleaning and Metric Calculation ---\n",
        "    if 'symbol' not in df.columns:\n",
        "        df.reset_index(inplace=True)\n",
        "    df.set_index('symbol', inplace=True, drop=False)\n",
        "    df['value_pe'] = df['trailingPE'].apply(lambda x: x if x > 0 else None)\n",
        "    df['growth_rev'] = df['revenueGrowth'].fillna(0) * 100\n",
        "    df['momentum_52w'] = df['currentPrice'] / df['fiftyTwoWeekHigh']\n",
        "\n",
        "    # --- Scoring via Percentile Ranks ---\n",
        "    df['value_score'] = df['value_pe'].rank(ascending=False, pct=True)\n",
        "    df['growth_score'] = df['growth_rev'].rank(pct=True)\n",
        "    df['momentum_score'] = df['momentum_52w'].rank(pct=True)\n",
        "\n",
        "    # --- Composite Score ---\n",
        "    df['composite_score'] = (df['value_score'] * weights['value'] +\n",
        "                             df['growth_score'] * weights['growth'] +\n",
        "                             df['momentum_score'] * weights['momentum'])\n",
        "\n",
        "    # --- Final Ranking ---\n",
        "    ranked_df = df[[\n",
        "        'longName', 'value_pe', 'growth_rev', 'momentum_52w', 'composite_score'\n",
        "    ]].copy().dropna()\n",
        "    ranked_df.sort_values(by='composite_score', ascending=False, inplace=True)\n",
        "    return ranked_df\n",
        "\n",
        "# --- Part 2: Main Application Logic and Widgets ---\n",
        "\n",
        "# Define file paths\n",
        "local_cache_path = 'sp500_financial_data.csv'\n",
        "drive_cache_path = '/content/drive/My Drive/sp500_financial_data.csv'\n",
        "\n",
        "# Create a global variable to hold our main dataframe\n",
        "financial_df = None\n",
        "\n",
        "# Create UI Widgets\n",
        "style = {'description_width': 'initial'}\n",
        "use_drive_cb = widgets.Checkbox(value=True, description='Use Google Drive for Cache', style=style)\n",
        "force_refresh_cb = widgets.Checkbox(value=False, description='Force Refresh (ignore all cache)')\n",
        "load_button = widgets.Button(description=\"▶️ Load/Refresh\", button_style='success')\n",
        "log_output = widgets.Output()\n",
        "\n",
        "value_slider = widgets.FloatSlider(value=0.4, min=0, max=1.0, step=0.05, description='Value Weight:', style=style)\n",
        "growth_slider = widgets.FloatSlider(value=0.3, min=0, max=1.0, step=0.05, description='Growth Weight:', style=style)\n",
        "momentum_slider = widgets.FloatSlider(value=0.3, min=0, max=1.0, step=0.05, description='Momentum Weight:', style=style)\n",
        "\n",
        "# Function for the \"Load Data\" button\n",
        "def load_data_and_run(b):\n",
        "    global financial_df\n",
        "    with log_output:\n",
        "        clear_output(wait=True)\n",
        "        # 1. Check for cache in Google Drive first if requested\n",
        "        if use_drive_cb.value and not force_refresh_cb.value:\n",
        "            print(\"Trying to load cache from Google Drive...\")\n",
        "            drive.mount('/content/drive', force_remount=True)\n",
        "            if os.path.exists(drive_cache_path):\n",
        "                shutil.copyfile(drive_cache_path, local_cache_path)\n",
        "                print(f\"✅ Copied cache from Google Drive to local session.\")\n",
        "\n",
        "        # 2. Decide whether to fetch fresh data\n",
        "        if force_refresh_cb.value or not os.path.exists(local_cache_path):\n",
        "            tickers = get_sp500_tickers()\n",
        "            if tickers:\n",
        "                df = fetch_financial_data(tickers)\n",
        "                df.to_csv(local_cache_path)\n",
        "                print(f\"\\n💾 Saved fresh data to local cache: '{local_cache_path}'\")\n",
        "                if use_drive_cb.value:\n",
        "                    df.to_csv(drive_cache_path)\n",
        "                    print(f\"💾 Saved fresh data to Google Drive: '{drive_cache_path}'\")\n",
        "        else:\n",
        "            print(f\"📂 Using existing cache file.\")\n",
        "\n",
        "        # 3. Load the dataframe into the global variable for interactive use\n",
        "        financial_df = pd.read_csv(local_cache_path)\n",
        "        print(\"Data is loaded and ready for interactive screening.\")\n",
        "\n",
        "load_button.on_click(load_data_and_run)\n",
        "\n",
        "# Function to handle the interactive screening triggered by sliders\n",
        "def interactive_screening(value_w, growth_w, momentum_w):\n",
        "    global top_20_tickers\n",
        "    if financial_df is not None:\n",
        "        user_weights = {'value': value_w, 'growth': growth_w, 'momentum': momentum_w}\n",
        "        ranked_df = screen_and_score_stocks(financial_df.copy(), user_weights)\n",
        "\n",
        "        top_20_tickers = ranked_df.head(20).index.tolist()\n",
        "\n",
        "        # Display the results table\n",
        "        display(ranked_df.head(20))\n",
        "    else:\n",
        "        print(\"Adjust the bars to begin screening the candidates.\")\n",
        "\n",
        "# Link the interactive function to the sliders' output\n",
        "interactive_ui = widgets.interactive_output(interactive_screening, {\n",
        "    'value_w': value_slider,\n",
        "    'growth_w': growth_slider,\n",
        "    'momentum_w': momentum_slider\n",
        "})\n",
        "\n",
        "# Display the final UI layout\n",
        "print(\"--- Quantitative Screener for Candidate Generation ---\")\n",
        "print(\"First, click 'Load/Refresh'. Then, adjust sliders to see candidates.\")\n",
        "display(\n",
        "    widgets.VBox([\n",
        "        widgets.HBox([load_button, use_drive_cb, force_refresh_cb]),\n",
        "        log_output,\n",
        "        widgets.HBox([value_slider, growth_slider, momentum_slider]),\n",
        "        interactive_ui\n",
        "    ])\n",
        ")"
      ],
      "metadata": {
        "id": "jaa43xn2DTVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrgiupwA_Go9"
      },
      "source": [
        "## Step 4: Import and Initialize the Agent\n",
        "\n",
        "Now we import our custom-built agent and tools. The heavy lifting and complex logic are handled in the background by our `research_agent_colab.py` and `tools_colab.py` files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3Upy--r_Go-"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from research_agent_colab import ResearchAgent\n",
        "from tools_colab import get_stock_info\n",
        "\n",
        "# Initialize models\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.2)\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Instantiate the agent\n",
        "research_agent = ResearchAgent(llm=llm, embeddings_model=embeddings)\n",
        "\n",
        "print(\"AI Research Agent is initialized and ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 5: Run the scout agent to narrow down the results."
      ],
      "metadata": {
        "id": "SfI2D1-YIncM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 4: Scout Agent - Qualitative Triage (Improved Version) ---\n",
        "import json\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import warnings\n",
        "\n",
        "# Suppress common FutureWarnings from torch/huggingface to clean up the output\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"torch.nn.modules.module\")\n",
        "\n",
        "# UI Widgets\n",
        "scout_button = widgets.Button(description=\"🔍 Run Scout Agent on Top 20\", button_style='primary')\n",
        "scout_output = widgets.Output()\n",
        "\n",
        "def run_scout_process(b):\n",
        "    with scout_output:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        if 'top_20_tickers' not in globals() or not top_20_tickers:\n",
        "            print(\"❌ Error: No tickers found. Please run the quantitative screener first.\")\n",
        "            return\n",
        "\n",
        "        print(f\"🕵️ Running Scout Agent on {len(top_20_tickers)} candidates...\")\n",
        "        scout_results = []\n",
        "        pbar = tqdm(total=len(top_20_tickers), desc=\"Scouting candidates\")\n",
        "\n",
        "        for ticker in top_20_tickers:\n",
        "            company_name = financial_df[financial_df['symbol'] == ticker]['longName'].iloc[0]\n",
        "            result = research_agent.generate_scout_analysis(company_name, ticker)\n",
        "\n",
        "            # This try/except block is now more robust to prevent the KeyError\n",
        "            try:\n",
        "                # Clean the response and load as JSON\n",
        "                json_str = result['answer'].strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
        "                json_data = json.loads(json_str)\n",
        "                json_data['ticker'] = ticker\n",
        "                json_data['longName'] = company_name\n",
        "                scout_results.append(json_data)\n",
        "            except (json.JSONDecodeError, TypeError, KeyError):\n",
        "                # If JSON fails or keys are missing, append a default error record\n",
        "                scout_results.append({\n",
        "                    'ticker': ticker,\n",
        "                    'longName': company_name,\n",
        "                    'compelling_score': 0,\n",
        "                    'news_summary': 'Error parsing LLM response or search failed.',\n",
        "                    'positive_catalyst': False,\n",
        "                    'negative_catalyst': False\n",
        "                })\n",
        "\n",
        "            pbar.update(1)\n",
        "        pbar.close()\n",
        "\n",
        "        # Process and display results\n",
        "        results_df = pd.DataFrame(scout_results)\n",
        "        results_df.sort_values(by='compelling_score', ascending=False, inplace=True)\n",
        "\n",
        "        print(\"\\n--- ✅ Top Scouted Candidates ---\")\n",
        "        # Define columns to ensure they always exist, preventing KeyError\n",
        "        display_cols = ['ticker', 'longName', 'compelling_score', 'news_summary', 'positive_catalyst', 'negative_catalyst']\n",
        "        display(results_df[display_cols])\n",
        "\n",
        "        # Store final candidates\n",
        "        global final_candidates\n",
        "        final_candidates = results_df.head(5)['ticker'].tolist()\n",
        "        print(f\"\\n🏆 Top 5 candidates selected for deep-dive: {', '.join(final_candidates)}\")\n",
        "\n",
        "scout_button.on_click(run_scout_process)\n",
        "\n",
        "# Display the UI\n",
        "print(\"\\n--- Scout Agent Controls ---\")\n",
        "print(\"This step runs a lightweight search (1 query per stock) to rank candidates by news relevance.\")\n",
        "display(scout_button, scout_output)"
      ],
      "metadata": {
        "id": "a3_IMsenIkue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7N-MuU7_Go-"
      },
      "source": [
        "## Step 6: Run the Final Analysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 5: Final Deep-Dive Analysis on a Top Candidate ---\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from tqdm.notebook import tqdm\n",
        "from display_utils_colab import display_analysis # <<< CHANGE: Import the missing display utility\n",
        "\n",
        "# This cell uses the `final_candidates` list generated by the Scout Agent\n",
        "\n",
        "# --- UI Widgets for the Final Analysis Step ---\n",
        "deep_dive_button = widgets.Button(description=\"🚀 Run Deep-Dive Analysis on Top 5\", button_style='info')\n",
        "deep_dive_output = widgets.Output()\n",
        "\n",
        "def run_deep_dive_process(b):\n",
        "    with deep_dive_output:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        if 'final_candidates' not in globals() or not final_candidates:\n",
        "            print(\"❌ Error: No final candidates found. Please run the Scout Agent in the cell above first.\")\n",
        "            return\n",
        "\n",
        "        print(f\"🚀 Kicking off deep-dive analysis for {len(final_candidates)} top candidates...\")\n",
        "\n",
        "        accordion_children = []\n",
        "        company_titles = []\n",
        "\n",
        "        for ticker in tqdm(final_candidates, desc=\"Deep-Diving Candidates\"):\n",
        "            company_name = financial_df[financial_df['symbol'] == ticker]['longName'].iloc[0]\n",
        "            company_titles.append(f\"{company_name} ({ticker})\")\n",
        "\n",
        "            company_output = widgets.Output()\n",
        "\n",
        "            with company_output:\n",
        "                print(f\"Running full analysis for {company_name}...\")\n",
        "                print(\"Note: This is faster as it uses cached search results.\")\n",
        "\n",
        "                # --- 1. MARKET INVESTOR OUTLOOK ---\n",
        "                market_outlook_result = research_agent.generate_market_outlook(company_name, ticker)\n",
        "                display_analysis(\"Market Investor Outlook\", company_name, market_outlook_result)\n",
        "\n",
        "                # --- 2. VALUE INVESTOR ANALYSIS ---\n",
        "                value_analysis_result = research_agent.generate_value_analysis(company_name, ticker)\n",
        "                display_analysis(\"Value Investor Analysis\", company_name, value_analysis_result)\n",
        "\n",
        "                # --- 3. DEVIL'S ADVOCATE VIEW ---\n",
        "                devils_advocate_result = research_agent.generate_devils_advocate_view(company_name, ticker)\n",
        "                display_analysis(\"Devil's Advocate View\", company_name, devils_advocate_result)\n",
        "\n",
        "                # --- 4. FINAL CONSENSUS SUMMARY ---\n",
        "                final_summary = research_agent.generate_final_summary(\n",
        "                    market_outlook_result.get('answer', ''),\n",
        "                    value_analysis_result.get('answer', ''),\n",
        "                    devils_advocate_result.get('answer', '')\n",
        "                )\n",
        "                display_analysis(\"FINAL CONSENSUS SUMMARY\", company_name, final_summary, is_summary=True)\n",
        "\n",
        "            accordion_children.append(company_output)\n",
        "\n",
        "        # Create and display the final accordion\n",
        "        final_accordion = widgets.Accordion(children=accordion_children)\n",
        "        for i, title in enumerate(company_titles):\n",
        "            final_accordion.set_title(i, title)\n",
        "\n",
        "        print(\"\\n--- ✅ Final Analysis Complete ---\")\n",
        "        display(final_accordion)\n",
        "\n",
        "deep_dive_button.on_click(run_deep_dive_process)\n",
        "\n",
        "# Display the UI for this step\n",
        "print(\"\\n--- Deep-Dive Analysis Controls ---\")\n",
        "print(\"Click the button below to run the full, multi-perspective analysis on your top 5 scouted candidates.\")\n",
        "display(deep_dive_button, deep_dive_output)"
      ],
      "metadata": {
        "id": "RG5mZHnjSOxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bonus: Run custom analysis\n",
        "Enter a company name and its corresponding stock ticker below to begin the analysis."
      ],
      "metadata": {
        "id": "jX2H3SpxUE5Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wEpl5XP_Go_"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, HTML, clear_output\n",
        "# <<< CHANGE: Import the new display utility >>>\n",
        "from display_utils_colab import display_analysis\n",
        "\n",
        "company_name = input(\"Enter the company name (e.g., NVIDIA): \")\n",
        "stock_ticker = input(\"Enter the stock ticker (e.g., NVDA): \")\n",
        "\n",
        "clear_output(wait=True) # Clears the input prompts for a cleaner display\n",
        "\n",
        "# To get fresh data and not use the cache, you can uncomment the next line:\n",
        "# research_agent.clear_cache()\n",
        "\n",
        "# --- 1. KEY FINANCIAL DATA ---\n",
        "print(f\"--- 1. KEY FINANCIAL DATA for {stock_ticker.upper()} ---\")\n",
        "financial_data_raw = get_stock_info.run(stock_ticker) if stock_ticker else \"No ticker provided.\"\n",
        "display(HTML(f\"<div style='border: 1px solid #444; border-radius: 8px; padding: 20px; white-space: pre-wrap; font-family: monospace; line-height: 1.6; background-color: #2c2c2e; color: #f0f0f0;'>{financial_data_raw}</div>\"))\n",
        "\n",
        "# --- 2. AI-GENERATED MARKET INVESTOR OUTLOOK ---\n",
        "market_outlook_result = research_agent.generate_market_outlook(company_name, stock_ticker)\n",
        "display_analysis(\"2. AI-GENERATED MARKET INVESTOR OUTLOOK\", company_name, market_outlook_result)\n",
        "\n",
        "# --- 3. AI-GENERATED VALUE INVESTOR ANALYSIS ---\n",
        "value_analysis_result = research_agent.generate_value_analysis(company_name, stock_ticker)\n",
        "display_analysis(\"3. AI-GENERATED VALUE INVESTOR ANALYSIS\", company_name, value_analysis_result)\n",
        "\n",
        "# --- 4. AI-GENERATED DEVIL'S ADVOCATE VIEW ---\n",
        "devils_advocate_result = research_agent.generate_devils_advocate_view(company_name, stock_ticker)\n",
        "display_analysis(\"4. AI-GENERATED DEVIL'S ADVOCATE VIEW\", company_name, devils_advocate_result)\n",
        "\n",
        "# --- 5. FINAL CONSENSUS SUMMARY ---\n",
        "final_summary = research_agent.generate_final_summary(\n",
        "    market_outlook_result.get('answer', ''),\n",
        "    value_analysis_result.get('answer', ''),\n",
        "    devils_advocate_result.get('answer', '')\n",
        ")\n",
        "display_analysis(\"5. FINAL CONSENSUS SUMMARY\", company_name, final_summary, is_summary=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WWZV3FtKU8zo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}